{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk \n",
    "import nltk.tokenize\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  score\n",
      "0  A very, very, very slow-moving, aimless movie ...      0\n",
      "1  Not sure who was more lost - the flat characte...      0\n",
      "2  Attempting artiness with black & white and cle...      0\n",
      "3       Very little music or anything to speak of.        0\n",
      "4  The best scene in the movie was when Gerardo i...      1\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('imdb.csv', encoding = \"ISO-8859-1\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  score\n",
      "0  A very, very, very slow-moving, aimless movie ...      0\n",
      "1  Not sure who was more lost - the flat characte...      0\n",
      "2  Attempting artiness with black & white and cle...      0\n",
      "3       Very little music or anything to speak of.        0\n",
      "4  The best scene in the movie was when Gerardo i...      1\n"
     ]
    }
   ],
   "source": [
    "def count_aa_text(text):\n",
    "    a_count = 0\n",
    "    for element in text:\n",
    "        stop_count = 1\n",
    "        lower_text = element.lower()\n",
    "        tokenized_text = nltk.tokenize.word_tokenize(lower_text)\n",
    "        pos_tag_text = nltk.pos_tag(tokenized_text, tagset='universal')\n",
    "        for x in pos_tag_text:\n",
    "            token = x[0]\n",
    "            if token[0]=='.': # I wonder how elipses are tokenized???\n",
    "                stop_count = stop_count + 1\n",
    "            tag = x[1]\n",
    "            if tag=='ADJ' or tag == 'ADV':\n",
    "                a_count = a_count + 1\n",
    "            ratio = a_count/stop_count\n",
    "        return ratio\n",
    "\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.525089605734767\n"
     ]
    }
   ],
   "source": [
    "#list of features\n",
    "features= ['text']#,'a_count']\n",
    "#target variable\n",
    "target = 'score'\n",
    "\n",
    "#arrays and lists NOT dataframes and series\n",
    "X = df[features].values\n",
    "y = df[target].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123)\n",
    "#print(X_train)\n",
    "\n",
    "ratio_of_pos_to_neg = sum(y_train)/len(y_train)\n",
    "print(ratio_of_pos_to_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextStats(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    " #try to add in my function here \n",
    "    def transform(self, posts):\n",
    "        return [{#'length': len(text),\n",
    "                 #'num_sentences': text.count('.'),\n",
    "                'aa_ratio': count_aa_text(text)}\n",
    "                for text in posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_stats_pipeline_with_clf = Pipeline([\n",
    "                ('stats', TextStats()),  # returns a list of dicts\n",
    "                ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "                ('classifier', LogisticRegression(solver = 'liblinear', class_weight = 'balanced'))\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5240641711229946\n"
     ]
    }
   ],
   "source": [
    "text_stats_pipeline_with_clf.fit(X_train, y_train)\n",
    "print(text_stats_pipeline_with_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = text_stats_pipeline_with_clf.predict(X_test)\n",
    "y_pred_proba = text_stats_pipeline_with_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.53      0.57       109\n",
      "           1       0.44      0.51      0.47        78\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       187\n",
      "   macro avg       0.52      0.52      0.52       187\n",
      "weighted avg       0.54      0.52      0.53       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
